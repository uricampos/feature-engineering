{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What's Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Goal of Feature Engineering\n",
    "\n",
    "- make the data better suited to the problem at hand"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Advantages of performing feature engineering\n",
    "\n",
    "- improve's a model predictive performance\n",
    "\n",
    "- reduce computacional or data needs\n",
    "\n",
    "- improve interpretability of the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Guiding Principle of Feature Engineering\n",
    "\n",
    "- feature has to have a relationship with the target - useful\n",
    "\n",
    "- tranformations in the features become in essence a part of the model itself\n",
    "\n",
    "- what information can the model use to achieve its best performance?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mutal Information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "\n",
    "- construct a ranking with feature utility metric\n",
    "\n",
    "- the metric well used is called \"mutual information\"\n",
    "\n",
    "- it can detect any kind of relationship\n",
    "- it is:\n",
    "    - easy to use and interpret\n",
    "    - computationally efficient\n",
    "    - theoretically well-founded\n",
    "    - resistant to overfitting\n",
    "    - able to detec any kind of relationship"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mutual Information and What it Measures\n",
    "\n",
    "- describes relationship in terms of uncertainty\n",
    "\n",
    "- how many questions you expect the feature to answer about the target?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpreting Mutual Information Scores\n",
    "\n",
    "- When MI is zero, the quantities are independent: neither can tell you anything about the other\n",
    "\n",
    "- values aboce 2.0 or so are uncommon (it uses logarithmic quantity, so it increases very slowly)\n",
    "\n",
    "- MI can help you to understand the relative potential of a feature as a predictor of the target, considered by itself\n",
    "\n",
    "- It's possible for a feature to be very informative when interacting with other features, but not so informative all alone. MI can't detect interactions between features. It is a univariate metric\n",
    "\n",
    "- The actual usefulness of a feature depends on the model you use it with. A feature is only useful to the extent that its relationship with the target is one your model can learn. Just because a feature has a high MI score doesn't mean your model will be able to do anything with that information. You may need to transform the feature first to expose the association"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mathematical Transforms\n",
    "- Relationship among numerical features are often expressed through mathematical formulas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Counts\n",
    "\n",
    "- Features describing the presence or absence of something are aggregate by creating a count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building-Up and Breaking-Down Features\n",
    "\n",
    "- complex strings that can usefully be broken into simpler pieces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group Transforms\n",
    "\n",
    "- aggregate information across multiple row grouped by some category"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering With K-Means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "\n",
    "- unsupervised learning algorithms\n",
    "\n",
    "- clustering is to assign data points to groups based upon how similar the points are to each other"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cluster Labels as a Feature\n",
    "\n",
    "- single real-valued feature: \"binning\" or \"discretization\" transform\n",
    "\n",
    "- multiple features: \"multi-simensional binning\" (sometimes called vector quantization)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Means Clustering\n",
    "\n",
    "- algorithm that is intuitive and easy to apply in a feature engineering context\n",
    "\n",
    "- centroids\n",
    "\n",
    "- Voronoi tessallation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Principal Component Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "\n",
    "- partitioning of the dataset based on proximity\n",
    "\n",
    "- tipically applied to standardized data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA\n",
    "\n",
    "- instead of describing the data with the original features, we describe it with its axes of variation\n",
    "\n",
    "- The axes of variation become the new features\n",
    "\n",
    "- new features: principal components\n",
    "\n",
    "- weights: loadings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA for Feature Engineering\n",
    "\n",
    "- two ways of using it:\n",
    "    - descriptive technique\n",
    "    - use components themselves as features \n",
    "    <br/>\n",
    "    <br/>\n",
    "- only works with numeric features\n",
    "\n",
    "- is sensitive to scale\n",
    "\n",
    "- removing or constraining outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Target Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "\n",
    "- meant for categorical features\n",
    "\n",
    "- method of encoding categories as numbers\n",
    "\n",
    "- supervised feature engineering technique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Target Encoding\n",
    "\n",
    "- any kind of encoding that replaces a feature's categories with some number derived from the target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Smoothing\n",
    "\n",
    "- unknown categories\n",
    "\n",
    "- rare categories\n",
    "\n",
    "- the ideia is to blend the in-category average with the overall average"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
